import pandas as pd
import numpy as np
import torch
from sklearn.preprocessing import MinMaxScaler

def load_data(dataset: str):
    '''
    Loads data from numpy file
    '''
    print(f"Loading {dataset} data..")

    path = f"data/input/{dataset}"

    if dataset == "cf.csv":
        # Load and scale
        df = pd.read_csv(f"{path}").sort_values(by=["PATIENTNR", "DATE"]).drop(columns=["PATIENTNR", "DATE", "START_KAFTRIO"])
        values = scale(df.values)

        # Reshape data (num_seq, seq_len, num_feat)
        sequence_length = 5
        values = values.reshape(int(len(df) / sequence_length), sequence_length, df.shape[1])

    elif (dataset == "cf_subset_notime.csv") or (dataset == "cf_subset_time.csv"):
        # Load and scale
        df = pd.read_csv(f"{path}").sort_values(by=["PATIENTNR", "DATE"]).drop(columns=["PATIENTNR", "DATE"])
        values = scale(df.values)

        # Reshape data (num_seq, seq_len, num_feat)
        sequence_length = 5
        values = values.reshape(int(len(df) / sequence_length), sequence_length, df.shape[1])

    return torch.Tensor(values), df.columns

def scale(values):
    scaler = MinMaxScaler()
    return scaler.fit_transform(values)

def load_synthetic_data(dataset: str, model: str):
    '''
    Loads data from numpy file
    '''
    print(f"Loading {dataset} data generated by {model}..")

    path = f"output/syndata/{model}/{dataset}.npy"

    data = np.load(path)
    return torch.from_numpy(data).float()

def create_dummy_data(path):
    '''
    Generates dummy dataset
    '''
    
    print("Generating dummy data..")
    arr = np.random.randint(0, 101, size=(20,10, 4))
    np.save(path, arr)