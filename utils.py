import os
import pandas as pd
import numpy as np
import argparse
import torch
import pickle
from torch.utils.data import TensorDataset, random_split
import matplotlib.pyplot as plt
from typing import List

HOSPITAL_COLS = ['DIABETES', 'LIVER_DISEASE', 'PANCREAS', 'PSEUDOMONAS', 
                 'EMERGENCY', 'NEBULIZED', 'ORAL', 'KAFTRIO', 'SYMKEVI', 
                 'ORKAMBI', 'KALYDECO', 'HEIGHT', 'WEIGHT', 'BMI', 'AGE', 
                 'PPFEV1', 'Male', 'F508DEL', 'TIME_SINCE_LAST_EVENT']

def parse_args():
    '''
    Converts arguments into variables
    '''
    print("Parsing arguments..")

    parser = argparse.ArgumentParser()
    parser.add_argument('--dataset', type=str, help='What dataset should be used?', default='dummy', choices=['cf', 'sepsis', 'dummy'])
    parser.add_argument('--model', type=str, help='What model should be used?', default='RGAN', choices=['RGAN', 'TimeGAN'])
    parser.add_argument('--device', type=str, help='Device to be used', default=set_device())
    parser.add_argument('--seed', type=str, help='Seed to be used', default=None)
    parser.add_argument('--epochs', type=int, help='Number of epochs for training', default=100)
    parser.add_argument('--lr', type=float, help='Learning rate', default=0.001)
    parser.add_argument('--input_dim', type=int, help='Dimensions of input layer of generator', default=10)
    parser.add_argument('--hidden_dim', type=int, help='Dimensions of hidden layer', default=20)
    parser.add_argument('--latent_dim', type=int, help='Dimensions of the latent representation of TimeGAN', default=10)
    parser.add_argument('--batch_size', type=int, help='Number of sequences to be processed each iteration', default=1)

    args = parser.parse_args()
    return args

def set_device():
    device = (
        "cuda" if torch.cuda.is_available()
        else "mps"
        if torch.backends.mps.is_available()
        else "cpu"
    )
    print(f"Using {device} device")
    return device

def load_data(dataset: str):
    '''
    Loads data from numpy file
    '''
    print(f"Loading {dataset} data..")

    path = f"data/{dataset}"

    if dataset == "dummy":
        if not os.path.exists(f"{path}.npy"):
            create_dummy_data(path)
        return np.load(f"{path}.npy")
    
    values, columns = load_cf_data(f"{path}")
    return values, columns

def load_cf_data(path):
    values = np.load(f"{path}.npy")

    with open(f'{path}_columns.pkl', 'rb') as f:
        columns = pickle.load(f)

    return torch.from_numpy(values).float(), columns

def load_synthetic_data(dataset: str, model: str):
    '''
    Loads data from numpy file
    '''
    print(f"Loading {dataset} data generated by {model}..")

    path = f"output/syndata/{model}/{dataset}.npy"

    data = np.load(path)
    return torch.from_numpy(data).float()

def create_dummy_data(path):
    '''
    Generates dummy dataset
    '''
    
    print("Generating dummy data..")
    arr = np.random.randint(0, 101, size=(20,10, 4))
    np.save(path, arr)

def generate_noise(batch_size: int, seq_length: int, num_of_features: int):
    """
    Method to generate noise.

    Output: Noise of shape (batch_size, seq_len, input_dim).
    """
    return torch.randn(batch_size, seq_length, num_of_features)

def split_train_test(real_data: torch.Tensor, fake_data: torch.Tensor, learning_rate: float = None, train_size: float = 0.8, hidden_dim: int = 10):
    print("Splitting data into train and test...")

    assert real_data.shape[0] == fake_data.shape[0] # Check if data is balanced (equal number of synthetic and fake sequences)
    assert real_data.shape[1] == fake_data.shape[1] # check if fake and real data have same number of events per sequence
    assert real_data.shape[2] == fake_data.shape[2] # check if fake and real data have same number of features

    labels_real = torch.ones(real_data.shape[0], 1) # create labels for real data
    labels_fake = torch.zeros(fake_data.shape[0], 1) # create labels for fake data

    data = torch.concat([real_data, fake_data], dim=0) # Combine synthetic and real data
    labels = torch.concat([labels_real, labels_fake], dim=0) # Combine labels for synthetic and real data

    test_size = 1 - train_size
    dataset = TensorDataset(data, labels)
    train_data, test_data = random_split(dataset, [train_size, test_size]) # split in train and test data

    return train_data, test_data

def visualise(epochs: torch.Tensor, graphs: torch.Tensor | List[torch.Tensor], labelx: str, labely: str, titles: str | List[str], path):
    x_axis = np.array(list(range(epochs)))

    # Plot single graph
    if isinstance(graphs, torch.Tensor) & isinstance(titles, str): plt.semilogx(x_axis, graphs.numpy(), label = titles)
    elif isinstance(graphs, List) & isinstance(titles, List):
        assert len(graphs) == len(titles)

        # Loop through number of graphs to plot
        for i in range(len(graphs)):
                plt.semilogx(x_axis, graphs[i].numpy(), label = f"{titles[i]}")
    else:
        raise Warning("Number of titles doesn't match number of graphs to plot")


    plt.ylabel(labelx)
    plt.xlabel(labely)
    plt.legend()
    plt.savefig(f"output/images/{path}-{epochs}.png")
    plt.clf()